{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a20cc22-f10d-41bf-9a70-40495e6acd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import s3fs; import xarray as xr; import numpy as np\n",
    "import pandas as pd; import dask.array as da; import ocetrac\n",
    "import matplotlib.pyplot as plt; import cartopy.crs as ccrs\n",
    "import warnings; import expectexception\n",
    "warnings.filterwarnings('ignore')\n",
    "import netCDF4 as nc; import datetime as dt; import scipy\n",
    "import intake; import pprint\n",
    "# Allow multiple lines per cell to be displayed without print (default is just last line)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# Enable more explicit control of DataFrame display (e.g., to omit annoying line numbers)\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e2d33b-ad13-4639-b53f-6869b5d81878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load my functions\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "626b381d-c39f-4336-958b-8e2cab7dfada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "# for magic functions\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91f000e0-ce7c-409d-81d7-45b0c189e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to run use apply_ocetrac_to_CESM2LE, we need this cell first\n",
    "cat_url_orig = '/glade/collections/cmip/catalog/intake-esm-datastore/catalogs/glade-cesm2-le.json'\n",
    "coll_orig = intake.open_esm_datastore(cat_url_orig)\n",
    "subset = coll_orig.search(component='atm',variable='SST',frequency='month_1',experiment='historical')\n",
    "member_id_list = subset.df.member_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a62836a8-2e4a-40d3-87a1-93968f2697f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'component.experiment.stream.forcing_variant.variable'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum area: 349.0\n",
      "inital objects identified \t 21386\n",
      "final objects tracked \t 1203\n",
      "CPU times: user 5min 40s, sys: 53 s, total: 6min 33s\n",
      "Wall time: 6min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ensemble_member_val = 0\n",
    "radius_val = 3\n",
    "\n",
    "detrended,blobs = apply_ocetrac_to_CESM2LE(ensemble_member_val, 0.9, radius_val, 0.75, start_val=0, end_val=1980) # ~ 6.5 minutes per ensemble member\n",
    "SSTA_and_events = create_events_file(detrended, blobs)\n",
    "SSTA_and_events.to_netcdf('SSTA_and_events_{}_{}.nc'.format(ensemble_member_val, radius_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a68edbc-117e-4541-89ae-d5de09d88415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.5 ms, sys: 955 Âµs, total: 43.5 ms\n",
      "Wall time: 46.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load in nino indices\n",
    "nino34_first50 = xr.open_dataset('/glade/u/home/cassiacai/marine_heatwaves/data/nino34_first50.nc')\n",
    "nino34_last50 = xr.open_dataset('/glade/u/home/cassiacai/marine_heatwaves/data/nino34_last50.nc')\n",
    "\n",
    "nino4_first50 = xr.open_dataset('/glade/u/home/cassiacai/marine_heatwaves/data/nino4_first50.nc')\n",
    "nino4_last50 = xr.open_dataset('/glade/u/home/cassiacai/marine_heatwaves/data/nino4_last50.nc')\n",
    "\n",
    "# rename nino file variables\n",
    "nino34_first50['nino34_ind'] = nino34_first50['SST']\n",
    "nino34_first50 = nino34_first50.drop(['SST'])\n",
    "\n",
    "nino4_first50['nino4_ind'] = nino4_first50['SST']\n",
    "nino4_first50 = nino4_first50.drop(['SST'])\n",
    "\n",
    "# nino indices for our specific ensemble member\n",
    "nino34_ens0 = nino34_first50.nino34_ind[ensemble_member_val,:]\n",
    "nino4_ens0 = nino4_first50.nino4_ind[ensemble_member_val,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c21816-a3a0-4974-90e2-162016802f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.62 ms, sys: 0 ns, total: 1.62 ms\n",
      "Wall time: 9.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load our land mask file\n",
    "land_mask = np.load('/glade/u/home/cassiacai/marine_heatwaves/data/SST_land.npy')\n",
    "land_mask[land_mask > 0] = np.nan\n",
    "land_mask[land_mask == 0.] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c8d0273-c5b2-4851-addd-be23912b5232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1203 mhws in this ensemble member!\n"
     ]
    }
   ],
   "source": [
    "SSTA_and_events =  xr.open_dataset('SSTA_and_events_0_3.nc')\n",
    "total_no_mhws = number_of_mhws(SSTA_and_events)\n",
    "print('There are', total_no_mhws, 'mhws in this ensemble member!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c7cba7a-8cb9-42a6-8270-4aa0576faac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on one marine heatwave\n",
    "mhw_id = 35\n",
    "event_file = SSTA_and_events\n",
    "\n",
    "duration = calc_duration(event_file, mhw_id)\n",
    "cumulative_intensity, cumulative_intensity_monthly = calc_cumulativeintensity(event_file, mhw_id)\n",
    "mean_intensity, mean_intensity_monthly = calc_meanintensity(event_file, mhw_id)\n",
    "max_intensity, max_intensity_monthly = calc_maximumintensity(event_file, mhw_id)\n",
    "std_intensity, std_intensity_monthly = calc_stdintensity(event_file, mhw_id)\n",
    "coords_full, spatial_extents, max_spatial_extent, max_spatial_extent_time, mean_spatial_extent, cumulative_spatial_extent = calc_spatialextent(event_file, mhw_id)\n",
    "perimeters = calc_perimeter(event_file, mhw_id)\n",
    "percperivarea = calc_percperimetervsarea(spatial_extents, perimeters)\n",
    "perc_sharedarea_ls = calc_compltodeform(coords_full, spatial_extents)\n",
    "deform = calc_deform(perc_sharedarea_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3f2485f2-5b60-4cf9-97e1-8c6eae553537",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Not necessary to run this cell\n",
    "# previously \n",
    "\n",
    "# took about 36 minutes\n",
    "initialization_SSTA_ar = np.zeros((no_mhws,192,288))\n",
    "duration_ar = np.zeros((no_mhws))\n",
    "initialization_when_ar = np.zeros((no_mhws))\n",
    "\n",
    "for mhw_id in range(1,no_mhws): # no_mhws  \n",
    "    for_one_mhw = SSTA_and_events.where(SSTA_and_events.labels==mhw_id, drop=False)\n",
    "    \n",
    "    \n",
    "    mhw_when = np.argwhere(for_one_mhw.labels.max(axis=(1,2)).values > 0.)\n",
    "    first_timestep = mhw_when[0][0]\n",
    "    initialization_when_ar[mhw_id] = first_timestep\n",
    "    initialization_SSTA_ar[mhw_id,:,:] = for_one_mhw.SSTA[first_timestep,:,:].values\n",
    "    \n",
    "    duration = calc_duration(SSTA_and_events, mhw_id)\n",
    "    duration_ar[mhw_id] = duration\n",
    "    \n",
    "# np.save('initialization_SSTA_ar_0.npy', initialization_SSTA_ar)    \n",
    "# initialization_SSTA_ar_0 = np.load('initialization_SSTA_ar_0.npy')\n",
    "\n",
    "# np.save('duration_ar_0.npy', duration_ar)    \n",
    "# duration_ar_0 = np.load('duration_ar_0.npy')\n",
    "\n",
    "# np.save('initialization_when_ar_0.npy', initialization_when_ar)    \n",
    "# initialization_when_ar_0 = np.load('initialization_when_ar_0.npy')\n",
    "\n",
    "initialization_SSTA_ar_0 = np.load('initialization_SSTA_ar_0.npy')\n",
    "duration_ar_0 = np.load('duration_ar_0.npy')\n",
    "initialization_when_ar_0 = np.load('initialization_when_ar_0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d88bb9a-fd4b-47b7-895c-7bb998ee2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def number_of_mhws(event_file):\n",
    "    return len(np.unique(event_file.labels)) - 1\n",
    "\n",
    "def calc_duration(event_file, mhw_id):\n",
    "    return len(event_file.where(event_file.labels==mhw_id, drop=True).time)\n",
    "\n",
    "def calc_cumulativeintensity(event_file, mhw_id):\n",
    "    for_one_mhw = event_file.where(event_file.labels==mhw_id, drop=True)\n",
    "    cumulative_intensity = np.nansum(for_one_mhw.SSTA)\n",
    "    cumulative_intensity_monthly = for_one_mhw.SSTA.sum(axis=(1,2)).values\n",
    "    return cumulative_intensity, cumulative_intensity_monthly\n",
    "\n",
    "def calc_meanintensity(event_file, mhw_id):\n",
    "    for_one_mhw = event_file.where(event_file.labels==mhw_id, drop=True)\n",
    "    mean_intensity = np.nanmean(for_one_mhw.SSTA)\n",
    "    mean_intensity_monthly = for_one_mhw.SSTA.mean(axis=(1,2)).values\n",
    "    return mean_intensity, mean_intensity_monthly\n",
    "\n",
    "def calc_maximumintensity(event_file, mhw_id):\n",
    "    for_one_mhw = event_file.where(event_file.labels==mhw_id, drop=True)\n",
    "    max_intensity = np.nanmax(for_one_mhw.SSTA)\n",
    "    max_intensity_monthly = for_one_mhw.SSTA.max(axis=(1,2)).values\n",
    "    return max_intensity, max_intensity_monthly\n",
    "\n",
    "def calc_stdintensity(event_file, mhw_id):\n",
    "    for_one_mhw = event_file.where(event_file.labels==mhw_id, drop=True)\n",
    "    std_intensity = np.nanstd(for_one_mhw.SSTA)\n",
    "    std_intensity_monthly = for_one_mhw.SSTA.std(axis=(1,2)).values\n",
    "    return std_intensity, std_intensity_monthly\n",
    "\n",
    "def calc_spatialextent(event_file, mhw_id):\n",
    "    for_one_mhw = event_file.where(event_file.labels==mhw_id, drop=True)\n",
    "    spatial_extents = []\n",
    "    coords_full = []\n",
    "    for i in range(len(for_one_mhw.time)):\n",
    "        for_onetimestep_stacked = for_one_mhw.labels[i,:,:].stack(zipcoords=['lat','lon'])\n",
    "        intermed = for_onetimestep_stacked[for_onetimestep_stacked.notnull()].zipcoords.values\n",
    "        lats = [x[0] for x in intermed]; lons = [x[1] for x in intermed]\n",
    "        coords = list(zip(lats, lons))\n",
    "        coords_full.append(coords)\n",
    "        y,x=zip(*coords)\n",
    "        dlon = [np.cos(y[c]*np.pi/180)*(111.320*1) for c in np.arange(0, len(coords))]; dlat = (110.574 *1) * np.ones(len(dlon))\n",
    "        area = np.sum(dlon*dlat)\n",
    "        spatial_extents.append(area)\n",
    "    max_spatial_extent = np.max(spatial_extents)\n",
    "    max_spatial_extent_time = np.argmax(spatial_extents)\n",
    "    mean_spatial_extent = np.mean(spatial_extents)\n",
    "    cumulative_spatial_extent = np.sum(spatial_extents)\n",
    "    return coords_full, spatial_extents, max_spatial_extent, max_spatial_extent_time, mean_spatial_extent, cumulative_spatial_extent\n",
    "\n",
    "def initialization(event_file, mhw_id):\n",
    "    for_one_mhw = event_file.where(event_file.labels==mhw_id, drop=False)\n",
    "    mhw_when = np.argwhere(for_one_mhw.labels.max(axis=(1,2)).values > 0.)\n",
    "    first_timestep = mhw_when[0][0]\n",
    "    bymonth = np.resize(np.arange(1,13),12*166)[1:-11]\n",
    "    month = bymonth[first_timestep]\n",
    "    return first_timestep, for_one_mhw.SSTA[first_timestep,:,:].values, month\n",
    "\n",
    "from skimage.measure import find_contours\n",
    "from haversine import haversine, Unit\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def calc_perimeter(event_file, mhw_id):\n",
    "    for_one_mhw = event_file.where(event_file.labels==mhw_id, drop=False)\n",
    "    first_timestep, first_array, month = initialization(event_file, mhw_id)\n",
    "    timesteps_to_choose_from = np.arange(first_timestep, first_timestep+duration)\n",
    "\n",
    "    convert_long_range = interp1d([0,360],[-180,180])\n",
    "    perimeter_ls = []\n",
    "    for i in timesteps_to_choose_from:\n",
    "        bw = for_one_mhw.labels[i,:,:].values > 0\n",
    "        contours = find_contours(bw)\n",
    "        distance_ls = []\n",
    "        for contour_num in range(len(contours)):\n",
    "            latitudes = for_one_mhw.lat.values[contours[contour_num][:,0].astype(int)]\n",
    "            longitudes = for_one_mhw.lon.values[contours[contour_num][:,1].astype(int)]    \n",
    "            coords = list(zip(latitudes, convert_long_range(longitudes)))\n",
    "\n",
    "            for i in range(len(coords)-1):\n",
    "                distance = haversine(coords[i], coords[i+1],Unit.KILOMETERS)\n",
    "                distance_ls.append(distance)\n",
    "            distance_ls.append(haversine(coords[len(coords)-1], coords[0],Unit.KILOMETERS))\n",
    "        perimeter = np.sum(distance_ls)\n",
    "        perimeter_ls.append(perimeter)\n",
    "    return perimeter_ls  \n",
    "\n",
    "def calc_percperimetervsarea(spatial_extents, perimeters):\n",
    "    return (np.asarray(perimeters)/np.asarray(spatial_extents))*100\n",
    "\n",
    "def convert_from_timeres_to_months(time_step):\n",
    "    bymonth = np.resize(np.arange(1,13),12*166)[1:-11]\n",
    "    month = bymonth[first_timestep]\n",
    "    return month\n",
    "\n",
    "def calc_compltodeform(coords_full, spatial_extents):\n",
    "    perc_sharedarea_ls = []\n",
    "    for i in range(len(coords_full)-1):\n",
    "        a_set = set(coords_full[i])\n",
    "        b_set = set(coords_full[i+1])\n",
    "        if a_set & b_set:\n",
    "            coords = a_set & b_set\n",
    "            y,x=zip(*coords)\n",
    "            dlon = [np.cos(y[c]*np.pi/180)*(111.320*1) for c in np.arange(0, len(coords))]; dlat = (110.574 *1) * np.ones(len(dlon))\n",
    "            sharedarea = np.sum(dlon*dlat)\n",
    "            perc_sharedarea_ls.append((sharedarea/ (spatial_extents[i] + spatial_extents[i+1]))*100)\n",
    "        else:\n",
    "            sharedareaarea = 0\n",
    "            perc_sharedarea_ls.append((sharedarea/ (spatial_extents[i] + spatial_extents[i+1]))*100)\n",
    "    return perc_sharedarea_ls\n",
    "\n",
    "def calc_deform(perc_sharedarea_ls):\n",
    "    return np.asarray(100 - np.asarray(perc_sharedarea_ls))\n",
    "\n",
    "def calc_whenlargesmall(spatial_extents):\n",
    "    when_large = (np.argmax(spatial_extents) / len(spatial_extents))*100\n",
    "    when_small = (np.argmin(spatial_extents) / len(spatial_extents))*100\n",
    "    return when_large, when_small\n",
    "\n",
    "def cross_correlation_spat(event_file, mhw_id):\n",
    "    for_one_mhw = event_file.where(event_file.labels==mhw_id, drop=False)\n",
    "    first_timestep, first_array, month = initialization(event_file, mhw_id)\n",
    "    timesteps_to_choose_from = np.arange(first_timestep, first_timestep+duration)\n",
    "    cc_image_array = np.zeros((len(timesteps_to_choose_from), 192,288))    \n",
    "\n",
    "    for i in range(len(timesteps_to_choose_from[:-1])):\n",
    "        image = for_one_mhw.SSTA[timesteps_to_choose_from[i],:,:].values\n",
    "        image = np.nan_to_num(image)\n",
    "        offset_image = for_one_mhw.SSTA[timesteps_to_choose_from[i+1],:,:].values\n",
    "        offset_image = np.nan_to_num(offset_image)\n",
    "        image_product = np.fft.fft2(image) * np.fft.fft2(offset_image).conj()\n",
    "        cc_image = np.fft.fftshift(np.fft.ifft2(image_product))\n",
    "        cc_image_array[i,:,:] = np.real(cc_image)\n",
    "    return cc_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ceb900-0d84-4558-999b-c1805d5d1903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "test-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
