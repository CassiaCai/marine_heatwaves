#!/usr/bin/env python
# ---------------------------------------------------------------------------------------------------------
##### Import all necessary (and some unnecessary packages in case we need them)
import s3fs; import xarray as xr; import numpy as np
import pandas as pd;import dask.array as da; import ocetrac
import matplotlib.pyplot as plt; import cartopy.crs as ccrs
import warnings; import expectexception
warnings.filterwarnings('ignore')
import netCDF4 as nc; import datetime as dt; import scipy; import intake; import pprint
# ---------------------------------------------------------------------------------------------------------
##### Open original collection description file
cat_url_orig = '/glade/collections/cmip/catalog/intake-esm-datastore/catalogs/glade-cesm2-le.json'
coll_orig = intake.open_esm_datastore(cat_url_orig)

subset = coll_orig.search(component='atm',variable='SST',frequency='month_1',experiment='historical')
subset_as_df = subset.df
grouped_df_subset = subset_as_df.groupby('member_id')
# ---------------------------------------------------------------------------------------------------------
##### Load all 100 ensemble members into a list called SST_full so that it is easier to manipulate
##### This takes a lot of memory space!!
%%time
i = 1
SST_full = []
for l, ent in grouped_df_subset:
    print(i, l)
    subset = coll_orig.search(component='atm',variable='SST',frequency='month_1',experiment='historical',member_id=l)
    dsets = subset.to_dataset_dict(zarr_kwargs={"consolidated": True}, storage_options={"anon": True})
    key = list(dsets.keys())[0]
    ds = dsets[str(key)]
    SST_full.append(ds.SST.isel(member_id=0).load())
    i+= 1
# ---------------------------------------------------------------------------------------------------------
##### Calculate the ensemble mean across all ensemble members and save ensemble mean
##### CPU times: user 5min 47s, sys: 19.2 s, total: 6min 6s
##### Wall time: 6min 49s
##### around 50 GB
%%time
ensemble_mean = sum(SST_full)/len(SST_full)
ensemble_mean
ensemble_mean._to_netcdf('ensemble_mean.nc')
ensemble_mean.close()
print ('finished saving')
# ---------------------------------------------------------------------------------------------------------
##### Remove the ensemble mean from each of the ensemble members (one-on-one subtraction)?
##### For example: (ensemble_member_I) - (ensemble_mean) = (ensemble_member_Inew)
SST_full_no_mean = []
for i in range(100):
    SST_full_no_mean.append(SST_full[i]-ensemble_mean)
##### Save as xarray. Some steps were changed here so that this session would not take too much memory. 
%%time # How can I streamline this? Try to save as a .zarr file.
newfile = xr.concat([SST_full[0], SST_full[17], SST_full[34], SST_full[51],
                    SST_full[1], SST_full[18], SST_full[35], SST_full[52],
                    SST_full[2], SST_full[19], SST_full[36], SST_full[53],
                    SST_full[3], SST_full[20], SST_full[37], SST_full[54], 
                    SST_full[4], SST_full[21], SST_full[38], SST_full[55],
                    SST_full[5], SST_full[22], SST_full[39], SST_full[56], 
                    SST_full[6], SST_full[23], SST_full[40], SST_full[57], 
                    SST_full[7], SST_full[24], SST_full[41], SST_full[58],
                    SST_full[8], SST_full[25], SST_full[42], SST_full[59],
                    SST_full[9], SST_full[26], SST_full[43], SST_full[60],
                    SST_full[10], SST_full[27], SST_full[44], SST_full[61],
                    SST_full[11], SST_full[28], SST_full[45], SST_full[62],
                    SST_full[12], SST_full[29], SST_full[46], SST_full[63], 
                    SST_full[13], SST_full[30], SST_full[47], SST_full[64],
                    SST_full[14], SST_full[31], SST_full[48], SST_full[65],
                    SST_full[15], SST_full[32], SST_full[49], SST_full[66], 
                    SST_full[16], SST_full[33], SST_full[50], SST_full[67],
                    SST_full[68], SST_full[69], SST_full[70], SST_full[71],
                    SST_full[72], SST_full[73], SST_full[74], SST_full[75],
                    SST_full[76], SST_full[77], SST_full[78], SST_full[79],
                    SST_full[80], SST_full[81], SST_full[82], SST_full[83],
                    SST_full[84], SST_full[85], SST_full[86], SST_full[87],
                    SST_full[88], SST_full[89], SST_full[90], SST_full[91],
                    SST_full[92], SST_full[93], SST_full[94], SST_full[95],
                    SST_full[96], SST_full[97], SST_full[98], SST_full[99],
                    ],dim='member_id')
newfile.to_netcdf('SSTA_full.nc', encoding={'dis': {'zlib': True}})

# ---------------------------------------------------------------------------------------------------------
##### We now have saved files. Let's take a look.
SST_full = xr.open_dataset('SST_full.nc')
print(SST_full)

SSTA_full = xr.open_dataset('SSTA_full.nc')
print(SSTA_full)
# ---------------------------------------------------------------------------------------------------------
##### More concrete steps:
##### Try 1: set range (40N to 50N) and (150W to 120W) first. Then run Ocetrac
%%time
SSTA_full_new = SSTA_full.where((SSTA_full.lat >= 39.109948) & (SSTA_full.lat <= 50.418848) 
                        &(SSTA_full.lon >= 200.0) & (SSTA_full.lon <= 236.),drop=True)

threshold = SSTA_full_new.groupby('time.month').quantile(0.9,dim=('time')) 
features_ssta = SSTA_full_new.where(SSTA_full_new.groupby('time.month')>=threshold, other=np.nan)
features_ssta

%%time
features_ssta= features_ssta.load()

full_mask_land = features_ssta
full_masked = full_mask_land.where(full_mask_land != 0)

binary_out_afterlandmask=np.isfinite(full_masked)

print(binary_out_afterlandmask)

newmask_1 = SST_full_new.SST.isel(member_id=0)
newmask = newmask_1.where(newmask_1 != 0)

newmasked = np.isfinite(newmask)

Tracker = ocetrac.Tracker(binary_out_afterlandmask[:,:,:], newmasked[1850,:,:], radius=1, min_size_quartile=0., timedim = 'time', xdim = 'lon', ydim='lat', positive=True)
blobs = Tracker.track()
##### !! ERROR: ValueError: Found only zeros in `mask` input. The mask should indicate valid regions with values of 1
##### !! ERROR: Check why this does not give me any MHWs. 
##### !! ATTEMPT: On OISST code. Are there objects across the threshold? Still keeping objects? When is this actually breaking?
# ---------------------------------------------------------------------------------------------------------
##### More concrete steps:
##### Try 2: Run Ocetrac on the entire grid. Then look at data only from range (40N to 50N) and (150W to 120W)
##### Takes a long time to run this step. I would have to wait forever to run 100 ensemble members. 
detrended = SSTA_full.SST.isel(member_id=0)

if detrended.chunks:
    detrended = detrended.chunk({'time': -1})
    
threshold = detrended.groupby('time.month').quantile(0.9,dim=('time')) 
features_ssta = detrended.where(detrended.groupby('time.month')>=threshold, other=np.nan)

%%time
features_ssta= features_ssta[:,:,:].load()

timed = 300
full_mask_land = features_ssta
full_masked = full_mask_land.where(full_mask_land != 0)
binary_out_afterlandmask=np.isfinite(full_masked)

binary_out_afterlandmask[timed,:,:].plot()

mask = np.isfinite(SST_full.SST.isel(time=0, member_id=0)) 
mask.plot()

%%time
Tracker = ocetrac.Tracker(binary_out_afterlandmask[:,:,:], mask, radius=6, min_size_quartile=0., timedim = 'time', xdim = 'lon', ydim='lat', positive=True)
blobs = Tracker.track()

blobs.attrs
np.nanmax(blobs['time'])
blobs.to_netcdf("blobs_ensemble1_rad6.nc")
# ---------------------------------------------------------------------------------------------------------
##### Save all files as .nc files into a folder.

# ---------------------------------------------------------------------------------------------------------
##### Analysis conducted in different file on Github called:  
